{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rana-Altaify/Alzheimer-s_ML_Model/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import libraries**"
      ],
      "metadata": {
        "id": "ajyi2qBNo_o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "ZJMqWQW61PwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Data**"
      ],
      "metadata": {
        "id": "fb06mM1spLNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import zipfile, os\n",
        "from tensorflow import keras\n",
        "\n",
        "repo_id = \"r2n2/bestalzheimer\"\n",
        "filename = \"alzhemier.zip\"\n",
        "\n",
        "file_path = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\")\n",
        "\n",
        "extract_dir = \"./alz_data\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\" Files extracted to:\", extract_dir)\n",
        "print(\"Folders:\", os.listdir(extract_dir))\n",
        "\n",
        "base_dir = os.path.join(extract_dir, \"Combined Dataset\")\n",
        "train_path = os.path.join(base_dir, \"train\")\n",
        "test_path = os.path.join(base_dir, \"test\")\n",
        "\n",
        "print(\" Train Path:\", train_path)\n",
        "print(\" Test Path:\", test_path)\n",
        "\n",
        "train_dataset = keras.utils.image_dataset_from_directory(\n",
        "    directory=train_path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    color_mode=\"rgb\",\n",
        ")\n",
        "\n",
        "test_dataset = keras.utils.image_dataset_from_directory(\n",
        "    directory=test_path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    color_mode=\"rgb\",\n",
        ")\n",
        "\n",
        "print(\" Datasets loaded successfully!\")\n",
        "print(\"Class Names:\", train_dataset.class_names)\n"
      ],
      "metadata": {
        "id": "fMGaTknp1ZeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_dir = \"./alz_data/Combined Dataset/train\"\n",
        "test_dir = \"./alz_data/Combined Dataset/test\"\n",
        "\n",
        "data = []\n",
        "for folder in [train_dir, test_dir]:\n",
        "    for class_name in os.listdir(folder):\n",
        "        class_path = os.path.join(folder, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            for img_name in os.listdir(class_path):\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    data.append({\n",
        "                        \"filepath\": os.path.join(class_path, img_name),\n",
        "                        \"label\": class_name\n",
        "                    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\" Total images:\", len(df))\n",
        "print(df[\"label\"].value_counts())\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nTraining samples per class:\")\n",
        "print(train_df[\"label\"].value_counts())\n",
        "print(\"\\nTesting samples per class:\")\n",
        "print(test_df[\"label\"].value_counts())\n",
        "\n",
        "train_df.to_csv(\"train_split.csv\", index=False)\n",
        "test_df.to_csv(\"test_split.csv\", index=False)\n",
        "\n",
        "print(\"\\n New stratified split saved successfully!\")\n"
      ],
      "metadata": {
        "id": "mQ6U9WBl3LlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "def load_and_preprocess_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_df[\"filepath\"].values, train_df[\"label\"].astype('category').cat.codes.values)\n",
        ")\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_df[\"filepath\"].values, test_df[\"label\"].astype('category').cat.codes.values)\n",
        ")\n",
        "\n",
        "train_dataset = train_dataset.map(load_and_preprocess_image).batch(32).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(load_and_preprocess_image).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "class_names = list(df[\"label\"].astype('category').cat.categories)\n",
        "print(\"Class names:\", class_names)\n"
      ],
      "metadata": {
        "id": "9ZxcLsjw6vdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def load_and_preprocess_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_df[\"filepath\"].values, train_df[\"label\"].astype('category').cat.codes.values))\n",
        "train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(32).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_df[\"filepath\"].values, test_df[\"label\"].astype('category').cat.codes.values))\n",
        "test_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "uiESRcGu69v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = Counter()\n",
        "for _, labels in train_dataset:\n",
        "    class_counts.update(labels.numpy())\n",
        "print(\"Class Counts:\", dict(class_counts))"
      ],
      "metadata": {
        "id": "up6bpAz47BgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "    image = preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "data = train_dataset.map(preprocess)\n",
        "test = test_dataset.map(preprocess)"
      ],
      "metadata": {
        "id": "UIayUyK87HyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transmodel = EfficientNetB0(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "ShvTY8XT7MBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transmodel.trainable = True\n",
        "set_trainable = False\n",
        "for layer in transmodel.layers:\n",
        "    if layer.name == \"block5a_expand_activation\":\n",
        "        set_trainable = True\n",
        "    layer.trainable = set_trainable\n"
      ],
      "metadata": {
        "id": "cG2Pf4Y-7PPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "x = transmodel.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=transmodel.input, outputs=output)\n"
      ],
      "metadata": {
        "id": "TP-YBwL67Sg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.01,\n",
        "    patience=11,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yHRIRxQZ7VZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    data,\n",
        "    batch_size=32,\n",
        "    epochs=59,\n",
        "    validation_data=test,\n",
        "    callbacks=[callback]\n",
        ")\n"
      ],
      "metadata": {
        "id": "Gkc6h6i97cdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ef = pd.DataFrame(history.history)\n",
        "ef[['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")\n",
        "ef[['loss', 'val_loss']].plot(title=\"Loss\")"
      ],
      "metadata": {
        "id": "xJbO98yaAK_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test)\n",
        "\n",
        "Actual = []\n",
        "predictions = []\n",
        "for images, labels in test:\n",
        "    Actual.extend(labels.numpy())\n",
        "    pred = model.predict(images)\n",
        "    predict = np.argmax(pred, axis=1)\n",
        "    predictions.extend(predict)\n",
        "\n",
        "x = classification_report(Actual, predictions, target_names=class_names)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "jM2tbpcPAU6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "\n",
        "conf_matrix = confusion_matrix(Actual, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "train_path = \"./alz_data/Combined Dataset/train\"\n",
        "class_names = sorted(os.listdir(train_path))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "osOEMTY5BUmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = np.trace(conf_matrix)\n",
        "incorrect = np.sum(conf_matrix) - correct\n",
        "\n",
        "sizes = [correct, incorrect]\n",
        "plt.pie(\n",
        "    sizes,\n",
        "    labels=[\"Correct\", \"Incorrect\"],\n",
        "    autopct=\"%1.1f%%\",\n",
        "    explode=[0.05, 0.05],\n",
        "    startangle=45,\n",
        "    colors=[\"#66b3ff\", \"#ff6666\"]\n",
        ")\n",
        "plt.title(\"Prediction Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Correct:\", correct)\n",
        "print(\"Incorrect:\", incorrect)"
      ],
      "metadata": {
        "id": "NjSi02j9BvZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy'][-1], history.history['val_accuracy'][-1]"
      ],
      "metadata": {
        "id": "QokIir1sEQrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"alzheimers_model.keras\")\n"
      ],
      "metadata": {
        "id": "BFQw1Bg4z0cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "import nest_asyncio\n",
        "\n",
        "model = tf.keras.models.load_model(\"alzheimers_model.keras\")\n",
        "\n",
        "def predict(image):\n",
        "    img = tf.image.resize(image, (224, 224))\n",
        "    if img.shape[-1] == 1:\n",
        "        img = tf.image.grayscale_to_rgb(img)\n",
        "    img = preprocess_input(img)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    preds = model.predict(img)\n",
        "    class_idx = np.argmax(preds)\n",
        "    confidence = float(np.max(preds))\n",
        "    class_names = [\"Mild Demented\", \"Moderate Demented\", \"Non Demented\", \"Very Mild Demented\"]\n",
        "    # العودة كـ dict للتوافق مع Gradio\n",
        "    result = {class_names[class_idx]: confidence}\n",
        "    return result\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"numpy\"),\n",
        "    outputs=gr.Label(num_top_classes=1),\n",
        "    title=\"Alzheimer MRI Classifier\",\n",
        "    description=\"Upload an MRI brain image and get the predicted class.\"\n",
        ")\n",
        "\n",
        "nest_asyncio.apply()\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "lJphv7Q2Wpat"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4Ae2deZnoG7cj5gvDHqa8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}